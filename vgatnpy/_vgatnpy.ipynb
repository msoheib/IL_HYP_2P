{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import filteranddeltaF as dFF_func\n",
    "import plotdeltaF_angles as df_plot\n",
    "import meanByangle as df_angle_mean\n",
    "\n",
    "from scipy.stats import ttest_ind, ttest_rel, zscore\n",
    "from roi_matching import process_matched_neurons, convert_mat_to_csv\n",
    "\n",
    "import alignment_code as df_align\n",
    "\n",
    "import osi_calculation as osi\n",
    "import gosiAnalysis as gosi\n",
    "import correlationori as corr\n",
    "import filtercriteria as filter_criteria\n",
    "import plotly.graph_objects as go\n",
    "import helper_functions as hf\n",
    "import helper_functions\n",
    "import snr_calculation as snr\n",
    "import cross_correlation as cc\n",
    "\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = \"vgatnpy\"\n",
    "pre = \"pre\"\n",
    "post= \"post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pre and post session data\n",
    "pre_df = pd.read_csv(rf'pre\\dFF_{ml}_pre.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "post_df = pd.read_csv(rf'post\\dFF_{ml}_post.csv', delimiter=\",\", header=0, decimal='.',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cell_pre_path = rf'J:\\My Drive\\0-Main\\1_STRESS\\{ml}\\pre\\iscell.npy'\n",
    "is_cell_post_path = rf'J:\\My Drive\\0-Main\\1_STRESS\\{ml}\\post\\iscell.npy'\n",
    "mat_file_path = rf'J:\\My Drive\\0-Main\\1_STRESS\\{ml}\\matched_rois.csv'\n",
    "\n",
    "df_match, list_pre, list_post = process_matched_neurons(mat_file_path, is_cell_pre_path, is_cell_post_path)\n",
    "\n",
    "\n",
    "#conmvert the floats to int in the list\n",
    "list_pre = [int(i) for i in list_pre]\n",
    "list_post = [int(i) for i in list_post]\n",
    "\n",
    "list_pre=helper_functions.convert_list_to_int_str(list_pre)\n",
    "list_post=helper_functions.convert_list_to_int_str(list_post)\n",
    "\n",
    "#filter pre_df and post_df based on matched neurons\n",
    "essen = helper_functions.get_essential_columns_as_list(pre_df)\n",
    "\n",
    "#combine essen list with list_pre\n",
    "list_pre.extend(essen)\n",
    "list_post.extend(essen)\n",
    "\n",
    "#filter the df column based on the list_pre and list_post\n",
    "pre_df = pre_df[list_pre]\n",
    "post_df = post_df[list_post]\n",
    "\n",
    "pre_df_seq_raw = hf.resequence_digit_columns(pre_df)\n",
    "post_df_seq_raw = hf.resequence_digit_columns(post_df)\n",
    "\n",
    "#drop the NaN rows in both df if either pre or post has NaN\n",
    "\n",
    "def drop_columns_with_nan_rows(df1, df2):\n",
    "    # Find columns with NaN in corresponding rows\n",
    "    mask = (df1.isna() | df2.isna()).any()\n",
    "    \n",
    "    # Drop those columns from both DataFrames\n",
    "    df1_cleaned = df1.loc[:, ~mask]\n",
    "    df2_cleaned = df2.loc[:, ~mask]\n",
    "    \n",
    "    return df1_cleaned, df2_cleaned\n",
    "\n",
    "\n",
    "pre_df_seq, post_df_seq = drop_columns_with_nan_rows(pre_df_seq_raw, post_df_seq_raw)\n",
    "\n",
    "pre_df_nonan , post_df_nonan = drop_columns_with_nan_rows(pre_df, post_df)\n",
    "\n",
    "# #replace the NaN values with 0\n",
    "# pre_df_seq.fillna(0, inplace=True)\n",
    "# post_df_seq.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pre and post session data\n",
    "pre_df = pd.read_csv(rf'pre\\dFF_{ml}_pre.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "post_df = pd.read_csv(rf'post\\dFF_{ml}_post.csv', delimiter=\",\", header=0, decimal='.',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_align.plot_raster_plotly(pre_df_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_align.plot_raster_plotly(post_df_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsive_preneurons_df, plotly_fig = filter_criteria.criteria_plot_population_response(pre_df_seq, inclusion_criterion=\"IC5\", z_threshold=1, secondsbefore=0.5, secondsafter=4, reorder_rois=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsive_postneurons_df, plotly_fig = filter_criteria.criteria_plot_population_response(post_df_seq[responsive_preneurons_df.columns], inclusion_criterion=None, z_threshold=1, secondsbefore=0.5, secondsafter=4, reorder_rois=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "filter_criteria.filter_criteria(pre_df_seq, inclusion_criterion=None, z_threshold=1, secondsbefore=1, secondsafter=6)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = hf.get_digit_columns(responsive_preneurons_df)\n",
    "\n",
    "df_angle_mean.calculate_mean_by_angle(responsive_preneurons_df, output_path='meanAngle_pre.csv',Select_columns_toplot=rois)\n",
    "pre_gosi_results = gosi.calculate_gosi(\"meanAngle_pre.csv\", column_names=rois)\n",
    "\n",
    "\n",
    "df_angle_mean.calculate_mean_by_angle(responsive_postneurons_df, output_path='meanAngle_post.csv',Select_columns_toplot=rois)\n",
    "post_gosi_results = gosi.calculate_gosi(\"meanAngle_post.csv\", column_names=rois)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_gosi_results.to_csv('post_gosi_results.csv', index=False)\n",
    "pre_gosi_results.to_csv('pre_gosi_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gosi.plot_gosi('pre_gosi_results.csv', \"post_gosi_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osi.calculate_and_plot(pre_gosi='pre_gosi_results.csv', mean_pre ='meanAngle_pre.csv',post_gosi =\"post_gosi_results.csv\", mean_post= \"meanAngle_post.csv\", osi_pre='osi_results_pre.csv',osi_post='osi_results_post.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr.process_and_visualize_snr(pre_df_seq, post_df_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_df, fit_results = gosi.process_and_plot_gosi_curve('meanAngle_post.csv', 'post_gosi_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_df, fit_results = gosi.process_and_plot_gosi_curve('meanAngle_pre.csv', 'pre_gosi_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.analyze_correlations(pre_df, post_df, name_of_v=\"Pupil size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.analyze_correlations(pre_df, post_df, correlate_with='speed', name_of_v='Locomotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.plot_cross_correlations(pre_df)\n",
    "cc.plot_cross_correlations(post_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.plot_cross_correlations(pre_df, correlate_with=\"speed\")\n",
    "cc.plot_cross_correlations(post_df, correlate_with=\"speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.plot_roi_correlation_matrix(pre_df)\n",
    "cc.plot_roi_correlation_matrix(post_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot_dff(df1, df2):\n",
    "    col_df1 = helper_functions.get_digit_columns(df1)\n",
    "    col_df2 = helper_functions.get_digit_columns(df2)\n",
    "\n",
    "    df1 = df1[col_df1]\n",
    "    df2 = df2[col_df2]\n",
    "\n",
    "    #takes the mean of each column\n",
    "    df1_mean_col = df1.mean()\n",
    "    df2_mean_col = df2.mean()\n",
    "\n",
    "    #take the mean across columns\n",
    "    df1_mean = df1.mean().mean()\n",
    "    df2_mean = df2.mean().mean()\n",
    "\n",
    "    #get the ci of the df1 and df2\n",
    "    df1_ci = df1.mean().sem()\n",
    "    df2_ci = df2.mean().sem()\n",
    "\n",
    "\n",
    "    print(df1_mean, df2_mean)\n",
    "\n",
    "\n",
    "    #plot the mean of the two df inone plot with each bar beingfrom df\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=(4, 7))\n",
    "    #set figure size\n",
    "    sns.barplot(x=[\"Pre-stress\", \"Post-stress\"], y=[df1_mean, df2_mean], , estimator='mean', yerr=[df1_ci, df2_ci], width = 0.5, capsize=0.1, ax=ax)\n",
    "    #plot the indivdual data points from df1_mean_col and df2_mean_col\n",
    "    sns.swarmplot(data=[df1_mean_col, df2_mean_col], color=\"0.2\", size=2)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "barplot_dff(pre_df_seq, post_df_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def barplot_dff(df1, df2):\n",
    "    col_df1 = helper_functions.get_digit_columns(df1)\n",
    "    col_df2 = helper_functions.get_digit_columns(df2)\n",
    "\n",
    "    df1 = df1[col_df1]\n",
    "    df2 = df2[col_df2]\n",
    "\n",
    "    # Takes the mean of each column\n",
    "    df1_mean_col = df1.mean()\n",
    "    df2_mean_col = df2.mean()\n",
    "\n",
    "    # Take the mean across columns\n",
    "    df1_mean = df1.mean().mean()\n",
    "    df2_mean = df2.mean().mean()\n",
    "\n",
    "    # Get the CI of the df1 and df2\n",
    "    df1_ci = df1.sem().mean()\n",
    "    df2_ci = df2.sem().mean()\n",
    "\n",
    "    print(df1_mean, df2_mean)\n",
    "\n",
    "    # Styling to make it more Prism-like\n",
    "    sns.set(style=\"ticks\", palette=\"pastel\")\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(4, 6))\n",
    "    bars = sns.barplot(x=[\"Pre-stress\", \"Post-stress\"], y=[df1_mean, df2_mean], yerr=[df1_ci, df2_ci], \n",
    "                        width=0.5, capsize=0.1, ax=ax, edgecolor=\"black\", linewidth=1.5, errcolor='gray', errwidth=1.5)\n",
    "\n",
    "    # Adding the individual points\n",
    "    mean_data = pd.DataFrame({'Condition': ['Pre-stress']*len(df1_mean_col) + ['Post-stress']*len(df2_mean_col),\n",
    "                              'Value': pd.concat([df1_mean_col, df2_mean_col], ignore_index=True)})\n",
    "    sns.swarmplot(x=\"Condition\", y=\"Value\", data=mean_data, color=\"0.25\", size=4, ax=ax, dodge=True)\n",
    "\n",
    "    # Enhancements for a Prism-like appearance\n",
    "    ax.set_ylabel(\"Mean DF/F%\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.grid(True, which='major', axis='y', linestyle='--', linewidth=0.5)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=10)\n",
    "    ax.tick_params(axis='x', which='major', labelsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming pre_df_seq and post_df_seq are defined elsewhere\n",
    "barplot_dff(pre_df_seq, post_df_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import helper_functions\n",
    "from scipy import stats\n",
    "\n",
    "def barplot_dff(file_pairs):\n",
    "    all_data = []\n",
    "    conditions = []\n",
    "    mice = []\n",
    "\n",
    "    for i, (df1, df2) in enumerate(file_pairs):\n",
    "        try:\n",
    "            col_df1 = helper_functions.get_digit_columns(df1)\n",
    "            col_df2 = helper_functions.get_digit_columns(df2)\n",
    "\n",
    "            df1 = df1[col_df1]\n",
    "            df2 = df2[col_df2]\n",
    "\n",
    "            # Store data\n",
    "            all_data.extend([df1.values.flatten(), df2.values.flatten()])\n",
    "            conditions.extend(['Pre-stress'] * df1.size + ['Post-stress'] * df2.size)\n",
    "            mice.extend([f'Mouse {i+1}'] * (df1.size + df2.size))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing data for Mouse {i+1}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"No valid data to process.\")\n",
    "        return None, None\n",
    "\n",
    "    # Create DataFrame for all data\n",
    "    combined_data = pd.DataFrame({\n",
    "        'Condition': conditions,\n",
    "        'Value': np.concatenate(all_data),\n",
    "        'Mouse': mice\n",
    "    })\n",
    "\n",
    "    # Perform t-test\n",
    "    pre_stress = combined_data[combined_data['Condition'] == 'Pre-stress']['Value']\n",
    "    post_stress = combined_data[combined_data['Condition'] == 'Post-stress']['Value']\n",
    "    t_statistic, p_value = stats.ttest_ind(pre_stress, post_stress)\n",
    "\n",
    "    # Calculate means and standard errors\n",
    "    summary_data = combined_data.groupby('Condition').agg({\n",
    "        'Value': ['mean', 'sem']\n",
    "    }).reset_index()\n",
    "    summary_data.columns = ['Condition', 'Mean', 'SEM']\n",
    "\n",
    "    # Plotting\n",
    "    sns.set(style=\"ticks\", palette=\"pastel\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 8))\n",
    "\n",
    "    # Bar plot\n",
    "    sns.barplot(x='Condition', y='Mean', data=summary_data,\n",
    "                capsize=0.1, ax=ax, edgecolor=\"black\", linewidth=1.5, errcolor='gray', errwidth=1.5)\n",
    "\n",
    "    # Swarm plot\n",
    "    sns.swarmplot(x=\"Condition\", y=\"Value\", data=combined_data, \n",
    "                  dodge=True, color=\"0.25\", size=2, ax=ax)\n",
    "\n",
    "    # Styling\n",
    "    ax.set_ylabel(\"Mean DF/F%\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.grid(True, which='major', axis='y', linestyle='--', linewidth=0.5)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=10)\n",
    "    ax.tick_params(axis='x', which='major', labelsize=10)\n",
    "\n",
    "    # Add p-value annotation\n",
    "    y_max = combined_data['Value'].max()\n",
    "    ax.text(0.5, y_max*1.1, f'p = {p_value:.4f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"T-statistic: {t_statistic}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "\n",
    "    return combined_data, summary_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wt1_pre = pd.read_csv(rf'J:\\My Drive\\0-Main\\1_STRESS\\wt1\\pre\\dFF_wt1_pre.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "df_wt1_post = pd.read_csv(rf'J:\\My Drive\\0-Main\\1_STRESS\\wt1\\post\\dFF_wt1_post.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "df_wt2_pre = pd.read_csv(rf'J:\\My Drive\\0-Main\\1_STRESS\\wt2\\pre\\dFF_wt2_pre.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "df_wt2_post = pd.read_csv(rf'J:\\My Drive\\0-Main\\1_STRESS\\wt2\\post\\dFF_wt2_post.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "df_wt3_pre = pd.read_csv(rf'J:\\My Drive\\0-Main\\1_STRESS\\wt3\\pre\\dFF_wt3_pre.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "df_wt3_post = pd.read_csv(rf'J:\\My Drive\\0-Main\\1_STRESS\\wt3\\post\\dFF_wt3_post.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "\n",
    "file_pairs = [(df_wt1_pre, df_wt1_post), (df_wt2_pre, df_wt2_post), (df_wt3_pre, df_wt3_post)]\n",
    "\n",
    "barplot_dff(file_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import helper_functions\n",
    "from scipy import stats\n",
    "\n",
    "def barplot_dff(file_pairs):\n",
    "    all_data = []\n",
    "    conditions = []\n",
    "    mice = []\n",
    "\n",
    "    for i, (df1, df2) in enumerate(file_pairs):\n",
    "        col_df1 = helper_functions.get_digit_columns(df1)\n",
    "        col_df2 = helper_functions.get_digit_columns(df2)\n",
    "\n",
    "        df1 = df1[col_df1]\n",
    "        df2 = df2[col_df2]\n",
    "\n",
    "        # Store data\n",
    "        all_data.extend([df1.values.flatten(), df2.values.flatten()])\n",
    "        conditions.extend(['Pre-stress'] * df1.size + ['Post-stress'] * df2.size)\n",
    "        mice.extend([f'Mouse {i+1}'] * (df1.size + df2.size))\n",
    "\n",
    "    # Create DataFrame for all data\n",
    "    combined_data = pd.DataFrame({\n",
    "        'Condition': conditions,\n",
    "        'Value': np.concatenate(all_data),\n",
    "        'Mouse': mice\n",
    "    })\n",
    "\n",
    "    # Perform nested t-test\n",
    "    t_statistic, p_value = stats.ttest_ind(\n",
    "        combined_data[combined_data['Condition'] == 'Pre-stress']['Value'],\n",
    "        combined_data[combined_data['Condition'] == 'Post-stress']['Value']\n",
    "    )\n",
    "\n",
    "    # Calculate means and standard errors\n",
    "    summary_data = combined_data.groupby('Condition').agg({\n",
    "        'Value': ['mean', 'sem']\n",
    "    }).reset_index()\n",
    "    summary_data.columns = ['Condition', 'Mean', 'SEM']\n",
    "\n",
    "    # Styling\n",
    "    sns.set(style=\"ticks\", palette=\"pastel\")\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(6, 8))\n",
    "    bars = sns.barplot(x='Condition', y='Mean', data=summary_data,\n",
    "                       capsize=0.1, ax=ax, edgecolor=\"black\", linewidth=1.5, errcolor='gray', errwidth=1.5)\n",
    "\n",
    "    # Adding the individual points\n",
    "    sns.swarmplot(x=\"Condition\", y=\"Value\", data=combined_data, \n",
    "                  dodge=True, color=\"0.25\", size=2, ax=ax)\n",
    "\n",
    "    # Enhancements for a Prism-like appearance\n",
    "    ax.set_ylabel(\"Mean DF/F%\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.grid(True, which='major', axis='y', linestyle='--', linewidth=0.5)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=10)\n",
    "    ax.tick_params(axis='x', which='major', labelsize=10)\n",
    "\n",
    "    # Add p-value annotation\n",
    "    y_max = combined_data['Value'].max()\n",
    "    ax.text(0.5, y_max*1.1, f'p = {p_value:.4f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"T-statistic: {t_statistic}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "\n",
    "    return combined_data, summary_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_wt1_pre = pd.read_csv(rf'J:\\My Drive\\0-Main\\1_STRESS\\wt1\\pre\\dFF_wt1_pre.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "df_wt1_post = pd.read_csv(rf'J:\\My Drive\\0-Main\\1_STRESS\\wt1\\post\\dFF_wt1_post.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "df_wt2_pre = pd.read_csv(rf'J:\\My Drive\\0-Main\\1_STRESS\\wt2\\pre\\dFF_wt2_pre.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "df_wt2_post = pd.read_csv(rf'J:\\My Drive\\0-Main\\1_STRESS\\wt2\\post\\dFF_wt2_post.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "df_wt3_pre = pd.read_csv(rf'J:\\My Drive\\0-Main\\1_STRESS\\wt3\\pre\\dFF_wt3_pre.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "df_wt3_post = pd.read_csv(rf'J:\\My Drive\\0-Main\\1_STRESS\\wt3\\post\\dFF_wt3_post.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "\n",
    "file_pairs = [(df_wt1_pre, df_wt1_post), (df_wt2_pre, df_wt2_post), (df_wt3_pre, df_wt3_post)]\n",
    "\n",
    "barplot_dff(file_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "labels = ['Crh', 'Pmch', 'Hcrt', 'Gal']\n",
    "values = [121, 0, 0, 0]\n",
    "\n",
    "# Colors (pastel)\n",
    "colors = ['#FFB3BA', '#BAFFC9', '#BAE1FF', '#FFFFBA']\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(4, 6))\n",
    "bars = plt.bar(labels, values, color=colors, edgecolor='black', linewidth=1.5, width=0.7)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('PVN RNA Probe Count', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.ylim(0, 140)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height}',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "# Customize grid\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Customize spines\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "# Remove top and right spines\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Thicken bottom and left spines\n",
    "plt.gca().spines['bottom'].set_linewidth(1.5)\n",
    "plt.gca().spines['left'].set_linewidth(1.5)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the second row from each mean column\n",
    "second_row_df1 = [df1_mean_col.iloc[1]]\n",
    "second_row_df2 = [df2_mean_col.iloc[1]]\n",
    "\n",
    "# Plot using seaborn's swarmplot\n",
    "sns.swarmplot(data=[second_row_df1, second_row_df2], color=\"0.2\", size=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
