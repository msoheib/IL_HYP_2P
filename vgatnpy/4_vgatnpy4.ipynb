{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import filteranddeltaF as dFF_func\n",
    "import plotdeltaF_angles as df_plot\n",
    "import meanByangle as df_angle_mean\n",
    "\n",
    "from scipy.stats import ttest_ind, ttest_rel, zscore\n",
    "from roi_matching import process_matched_neurons, convert_mat_to_csv, plot_matched_neurons_subset\n",
    "\n",
    "import alignment_code as df_align\n",
    "\n",
    "import osi_calculation as osi\n",
    "import gosiAnalysis as gosi\n",
    "import correlationori as corr\n",
    "import filtercriteria as filter_criteria\n",
    "import plotly.graph_objects as go\n",
    "import helper_functions as hf\n",
    "import helper_functions\n",
    "import snr_calculation as snr\n",
    "import cross_correlation as cc\n",
    "\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = \"vgatnpy\"\n",
    "pre = \"pre\"\n",
    "post= \"post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pre and post session data\n",
    "pre_df = pd.read_csv(rf'pre\\dFF_{ml}_pre.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "post_df = pd.read_csv(rf'post\\dFF_{ml}_post.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "\n",
    "iscell_pre_path = rf'J:\\My Drive\\0-Main\\1_STRESS\\{ml}\\pre\\iscell.npy'\n",
    "iscell_post_path = rf'J:\\My Drive\\0-Main\\1_STRESS\\{ml}\\post\\iscell.npy'\n",
    "matched_rois_path = rf'J:\\My Drive\\0-Main\\1_STRESS\\{ml}\\matched_rois.csv'\n",
    "\n",
    "\n",
    "final_matches, rois_pre, rois_post = process_matched_neurons(matched_rois_path, iscell_pre_path, iscell_post_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cell_pre_path = rf'J:\\My Drive\\0-Main\\1_STRESS\\{ml}\\pre\\iscell.npy'\n",
    "is_cell_post_path = rf'J:\\My Drive\\0-Main\\1_STRESS\\{ml}\\post\\iscell.npy'\n",
    "mat_file_path = rf'J:\\My Drive\\0-Main\\1_STRESS\\{ml}\\matched_rois.csv'\n",
    "\n",
    "df_match, list_pre, list_post = process_matched_neurons(mat_file_path, is_cell_pre_path, is_cell_post_path)\n",
    "\n",
    "\n",
    "#conmvert the floats to int in the list\n",
    "list_pre = [int(i) for i in list_pre]\n",
    "list_post = [int(i) for i in list_post]\n",
    "\n",
    "list_pre=helper_functions.convert_list_to_int_str(list_pre)\n",
    "list_post=helper_functions.convert_list_to_int_str(list_post)\n",
    "\n",
    "#filter pre_df and post_df based on matched neurons\n",
    "essen = helper_functions.get_essential_columns_as_list(pre_df)\n",
    "\n",
    "#combine essen list with list_pre\n",
    "list_pre.extend(essen)\n",
    "list_post.extend(essen)\n",
    "\n",
    "#filter the df column based on the list_pre and list_post\n",
    "pre_df = pre_df[list_pre]\n",
    "post_df = post_df[list_post]\n",
    "\n",
    "pre_df_seq_raw = hf.resequence_digit_columns(pre_df)\n",
    "post_df_seq_raw = hf.resequence_digit_columns(post_df)\n",
    "\n",
    "#drop the NaN rows in both df if either pre or post has NaN\n",
    "\n",
    "def drop_columns_with_nan_rows(df1, df2):\n",
    "    # Find columns with NaN in corresponding rows\n",
    "    mask = (df1.isna() | df2.isna()).any()\n",
    "    \n",
    "    # Drop those columns from both DataFrames\n",
    "    df1_cleaned = df1.loc[:, ~mask]\n",
    "    df2_cleaned = df2.loc[:, ~mask]\n",
    "    \n",
    "    return df1_cleaned, df2_cleaned\n",
    "# def drop_columns_with_nan_rows(df1, df2):\n",
    "#     # Ensure both DataFrames have the same columns\n",
    "#     common_columns = df1.columns.intersection(df2.columns)\n",
    "#     df1 = df1[common_columns]\n",
    "#     df2 = df2[common_columns]\n",
    "    \n",
    "#     # Create a mask for columns that have NaN in any row in either DataFrame\n",
    "#     mask = pd.concat([df1.isna().any(), df2.isna().any()], axis=1).any(axis=1)\n",
    "    \n",
    "#     # Get the column names to keep\n",
    "#     columns_to_keep = mask[~mask].index\n",
    "    \n",
    "#     # Select only the columns to keep in both DataFrames\n",
    "#     df1_cleaned = df1[columns_to_keep]\n",
    "#     df2_cleaned = df2[columns_to_keep]\n",
    "    \n",
    "#     return df1_cleaned, df2_cleaned\n",
    "\n",
    "pre_df_seq, post_df_seq = drop_columns_with_nan_rows(pre_df_seq_raw, post_df_seq_raw)\n",
    "pre_df_nonan , post_df_nonan = drop_columns_with_nan_rows(pre_df, post_df)\n",
    "\n",
    "# #replace the NaN values with 0\n",
    "# pre_df_seq.fillna(0, inplace=True)\n",
    "# post_df_seq.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pre and post session data\n",
    "pre_df = pd.read_csv(rf'pre\\dFF_{ml}_pre.csv', delimiter=\",\", header=0, decimal='.',engine='python')\n",
    "post_df = pd.read_csv(rf'post\\dFF_{ml}_post.csv', delimiter=\",\", header=0, decimal='.',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_align.plot_raster_plotly(pre_df_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_align.plot_raster_plotly(post_df_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsive_preneurons_df, plotly_fig = filter_criteria.criteria_plot_population_response(pre_df_seq, inclusion_criterion=\"IC5\", z_threshold=1, secondsbefore=0.5, secondsafter=4, reorder_rois=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsive_postneurons_df, plotly_fig = filter_criteria.criteria_plot_population_response(post_df_seq[post_df_seq.columns], inclusion_criterion=None, z_threshold=1, secondsbefore=0.5, secondsafter=4, reorder_rois=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=filter_criteria.criteria_plot_population_response(pre_df, inclusion_criterion=\"IC3\", z_threshold=1, secondsbefore=0.5, secondsafter=4, reorder_rois=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotdeltaF_angles\n",
    "plotdeltaF_angles.plot_deltaF_angles(responsive_preneurons_df,responsive_preneurons_df.columns[30:35], gaussian_sigma=5)\n",
    "plotdeltaF_angles.plot_deltaF_angles(responsive_postneurons_df,responsive_postneurons_df.columns[30:35], gaussian_sigma=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "filter_criteria.filter_criteria(responsive_preneurons_df, inclusion_criterion=None, z_threshold=1, secondsbefore=1, secondsafter=6)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "filter_criteria.filter_criteria(a, inclusion_criterion=None, z_threshold=1, secondsbefore=1, secondsafter=6)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "filter_criteria.filter_criteria(pre_df_seq, inclusion_criterion=None, z_threshold=1, secondsbefore=1, secondsafter=6)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_criteria.filter_criteria(post_df_seq, inclusion_criterion=None, z_threshold=1, secondsbefore=1, secondsafter=6)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = hf.get_digit_columns(responsive_preneurons_df)\n",
    "\n",
    "df_angle_mean.calculate_mean_by_angle(responsive_preneurons_df, output_path='meanAngle_pre.csv',Select_columns_toplot=rois)\n",
    "pre_gosi_results = gosi.calculate_gosi(\"meanAngle_pre.csv\", column_names=rois)\n",
    "\n",
    "\n",
    "df_angle_mean.calculate_mean_by_angle(responsive_postneurons_df, output_path='meanAngle_post.csv',Select_columns_toplot=rois)\n",
    "post_gosi_results = gosi.calculate_gosi(\"meanAngle_post.csv\", column_names=rois)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_gosi_results.to_csv('post_gosi_results.csv', index=False)\n",
    "pre_gosi_results.to_csv('pre_gosi_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gosi.plot_gosi('pre_gosi_results.csv', \"post_gosi_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osi.calculate_and_plot(pre_gosi='pre_gosi_results.csv', mean_pre ='meanAngle_pre.csv',post_gosi =\"post_gosi_results.csv\", mean_post= \"meanAngle_post.csv\", osi_pre='osi_results_pre.csv',osi_post='osi_results_post.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr.process_and_visualize_snr(pre_df_seq, post_df_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_df, fit_results = gosi.process_and_plot_gosi_curve('meanAngle_post.csv', 'post_gosi_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_df, fit_results = gosi.process_and_plot_gosi_curve('meanAngle_pre.csv', 'pre_gosi_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.analyze_correlations(pre_df, post_df, name_of_v=\"Pupil size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.analyze_correlations(pre_df, post_df, correlate_with='speed', name_of_v='Locomotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pre_df[\"pupil_size\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pre_df[\"speed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(post_df[\"speed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.plot_cross_correlations(pre_df)\n",
    "cc.plot_cross_correlations(post_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.plot_cross_correlations_around_stimuli(pre_df, correlate_with=\"pupil_size\", name_of_v='Pupil Size', time_window=10)\n",
    "cc.plot_cross_correlations_around_stimuli(post_df, correlate_with=\"pupil_size\", name_of_v='Pupil Size', time_window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.plot_cross_correlations_around_stimuli(pre_df, correlate_with=\"speed\", name_of_v='Locomotion', time_window=10)\n",
    "cc.plot_cross_correlations_around_stimuli(post_df, correlate_with=\"speed\", name_of_v='Locomotion', time_window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.plot_cross_correlations(pre_df, correlate_with=\"speed\", name_of_v='Locomotion')\n",
    "cc.plot_cross_correlations(post_df, correlate_with=\"speed\", name_of_v='Locomotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import stats\n",
    "# import helper_functions as hf\n",
    "\n",
    "# def plot_roi_correlation_comparison(df1, df2, alpha=0.05):\n",
    "#     \"\"\"\n",
    "#     Plot the correlation matrices of two DataFrames side by side, print correlation statistics,\n",
    "#     and create a bar plot comparing the percentage of significant correlations.\n",
    "    \n",
    "#     Args:\n",
    "#     df1, df2 (pandas.DataFrame): DataFrames containing the ROI data.\n",
    "#     alpha (float): Significance level for correlation tests.\n",
    "    \n",
    "#     Returns:\n",
    "#     None, but displays plots and prints statistics.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def process_df(df):\n",
    "#         roi_columns = hf.get_digit_columns(df)\n",
    "#         roi_df = df[roi_columns].copy()\n",
    "#         roi_df = roi_df.loc[:, (roi_df != 0).any(axis=0)]\n",
    "#         roi_df = roi_df.dropna(axis=1)\n",
    "#         return roi_df\n",
    "    \n",
    "#     roi_df1 = process_df(df1)\n",
    "#     roi_df2 = process_df(df2)\n",
    "    \n",
    "#     if roi_df1.empty or roi_df2.empty:\n",
    "#         print(\"Error: No valid ROI columns left after dropping zeros and NaNs.\")\n",
    "#         return\n",
    "    \n",
    "#     def compute_corr_stats(corr_matrix):\n",
    "#         n = corr_matrix.shape[0]\n",
    "#         tri_k = n * (n-1) // 2  # number of elements in upper triangle\n",
    "        \n",
    "#         # Compute p-values\n",
    "#         p_values = np.zeros_like(corr_matrix)\n",
    "#         for i in range(n):\n",
    "#             for j in range(i+1, n):  # Only upper triangle\n",
    "#                 r = corr_matrix.iloc[i, j]\n",
    "#                 t = r * np.sqrt((n-2) / (1-r**2))\n",
    "#                 p_values[i, j] = stats.t.sf(np.abs(t), n-2)*2\n",
    "        \n",
    "#         # Count significant correlations in upper triangle\n",
    "#         sig_corrs = np.sum(p_values[np.triu_indices(n, k=1)] < alpha)\n",
    "#         percent_sig = (sig_corrs / tri_k) * 100\n",
    "        \n",
    "#         # Calculate mean and median correlation from upper triangle\n",
    "#         corr_values = corr_matrix.values[np.triu_indices(n, k=1)]\n",
    "#         mean_corr = np.mean(corr_values)\n",
    "#         median_corr = np.median(corr_values)\n",
    "        \n",
    "#         return sig_corrs, tri_k, percent_sig, mean_corr, median_corr\n",
    "    \n",
    "#     corr_matrix1 = roi_df1.corr()\n",
    "#     corr_matrix2 = roi_df2.corr()\n",
    "    \n",
    "#     sig_corrs1, total_corrs1, percent_sig1, mean_corr1, median_corr1 = compute_corr_stats(corr_matrix1)\n",
    "#     sig_corrs2, total_corrs2, percent_sig2, mean_corr2, median_corr2 = compute_corr_stats(corr_matrix2)\n",
    "    \n",
    "#     # T-test for proportion of significant correlations\n",
    "#     def proportion_ttest(count1, nobs1, count2, nobs2):\n",
    "#         p1 = count1 / nobs1\n",
    "#         p2 = count2 / nobs2\n",
    "#         se = np.sqrt(p1 * (1 - p1) / nobs1 + p2 * (1 - p2) / nobs2)\n",
    "#         t = (p1 - p2) / se\n",
    "#         df = nobs1 + nobs2 - 2\n",
    "#         p_value = 2 * (1 - stats.t.cdf(np.abs(t), df))\n",
    "#         return t, p_value\n",
    "\n",
    "#     t_stat, p_value_ttest = proportion_ttest(sig_corrs1, total_corrs1, sig_corrs2, total_corrs2)\n",
    "    \n",
    "#     # Plotting correlation matrices\n",
    "#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7.5))\n",
    "    \n",
    "#     rwb_cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "    \n",
    "#     sns.heatmap(corr_matrix1, cmap=rwb_cmap, vmin=-1, vmax=1, center=0, ax=ax1)\n",
    "#     ax1.set_title(\"Correlation Matrix Pre-stress\", fontsize=16)\n",
    "    \n",
    "#     sns.heatmap(corr_matrix2, cmap=rwb_cmap, vmin=-1, vmax=1, center=0, ax=ax2)\n",
    "#     ax2.set_title(\"Correlation Matrix Post-stress\", fontsize=16)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "#     # GraphPad Prism-like theme adjustments\n",
    "#     plt.style.use('seaborn-white')  # Use a clean background\n",
    "#     fig, ax = plt.subplots(figsize=(4, 7))\n",
    "#     bar_width = 0.7\n",
    "#     index = np.arange(2)\n",
    "\n",
    "#     # Pastel colors\n",
    "#     colors = ['#aec7e8', '#98df8a']  # Pastel blue and green\n",
    "\n",
    "#     bars = plt.bar(index, [percent_sig1, percent_sig2], bar_width,\n",
    "#                 alpha=0.9, color=colors, label=['Pre Stress', 'Post Stress'], edgecolor='black')\n",
    "\n",
    "#     # Make the plot resemble GraphPad Prism's style\n",
    "#     plt.ylabel('Percentage', fontsize=12, fontweight='bold')\n",
    "#     plt.title('Ratio of ROIs with Significant Correlations', fontsize=14, fontweight='bold')\n",
    "#     plt.xticks(index, ('Pre-stress', 'Post-stress'), fontsize=11)\n",
    "#     plt.yticks(fontsize=11)\n",
    "#     plt.legend(frameon=False, fontsize=11)\n",
    "\n",
    "#     # Customize the axes and grid\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "#     ax.spines['left'].set_color('grey')\n",
    "#     ax.spines['bottom'].set_color('grey')\n",
    "#     ax.yaxis.grid(True, linestyle='--', which='major', color='lightgrey', alpha=0.7)  # Light horizontal grid lines\n",
    "\n",
    "#     # Add significance bar if the difference is significant\n",
    "#     if p_value_ttest < alpha:\n",
    "#         y_max = max(percent_sig1, percent_sig2)\n",
    "#         bar_height = y_max * 0.1\n",
    "#         plt.plot([index[0], index[1]], [y_max + bar_height, y_max + bar_height], color='black', linewidth=1.5)\n",
    "#         plt.text((index[0] + index[1]) / 2, y_max + bar_height * 1.1, f'*', \n",
    "#                  ha='center', va='bottom', fontsize=10)\n",
    "#         ax.set_ylim(top=(y_max + bar_height * 2))  # Adjust y-axis limit to accommodate the bar\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "#     # Print statistics\n",
    "#     print(f\"Dataset 1:\")\n",
    "#     print(f\"  Percentage of significant correlations: {percent_sig1:.2f}%\")\n",
    "#     print(f\"  Mean correlation: {mean_corr1:.4f}\")\n",
    "#     print(f\"  Median correlation: {median_corr1:.4f}\")\n",
    "#     print(f\"\\nDataset 2:\")\n",
    "#     print(f\"  Percentage of significant correlations: {percent_sig2:.2f}%\")\n",
    "#     print(f\"  Mean correlation: {mean_corr2:.4f}\")\n",
    "#     print(f\"  Median correlation: {median_corr2:.4f}\")\n",
    "    \n",
    "#     # Compute differences\n",
    "#     diff_percent_sig = percent_sig2 - percent_sig1\n",
    "#     diff_mean_corr = mean_corr2 - mean_corr1\n",
    "#     diff_median_corr = median_corr2 - median_corr1\n",
    "    \n",
    "#     # Fisher's r-to-z transformation for testing difference between correlations\n",
    "#     z1 = np.arctanh(mean_corr1)\n",
    "#     z2 = np.arctanh(mean_corr2)\n",
    "#     n1 = corr_matrix1.shape[0]\n",
    "#     n2 = corr_matrix2.shape[0]\n",
    "#     se_diff = np.sqrt(1/(n1-3) + 1/(n2-3))\n",
    "#     z = (z2 - z1) / se_diff\n",
    "#     p_value = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "    \n",
    "#     print(f\"\\nDifferences (Dataset 2 - Dataset 1):\")\n",
    "#     print(f\"  Difference in percentage of significant correlations: {diff_percent_sig:.2f}%\")\n",
    "#     print(f\"  Difference in mean correlation: {diff_mean_corr:.4f}\")\n",
    "#     print(f\"  Difference in median correlation: {diff_median_corr:.4f}\")\n",
    "#     print(f\"  P-value for difference in mean correlation: {p_value:.4f}\")\n",
    "#     print(f\"  P-value for difference in percentage of significant correlations (t-test): {p_value_ttest:.10f}\")\n",
    "\n",
    "# # Usage example:\n",
    "# plot_roi_correlation_comparison(pre_df, post_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.plot_roi_correlation_comparison(pre_df, post_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
